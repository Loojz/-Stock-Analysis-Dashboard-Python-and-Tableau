{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d33995-f178-47dd-bd25-55a1865063a4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Projekt: Aktien-Analyse-Dashboard - DAV\n",
    "\n",
    "Dieses Notebook ist für die Präsentation der Beschaffung, Verarbeitung und Anreicherung von Aktienkursdaten zuständig. Die hier erzeugten CSV-Dateien dienen als Datenquelle für mein interaktives Tableau-Dashboard. Es wurde als Projekt Arbeit für den Kurs \"Datenaufbereitung und -verarbeitung\" (Menden/ Butscher) THWS 2025 erstellt.\n",
    "\n",
    "**Prozess-Schritte:**\n",
    "1.  **Konfiguration:** Definition der Aktien (Ticker), des Zeitraums und technischer Parameter.\n",
    "2.  **Datenabruf:** Abruf der Kursdaten und Unternehmensinformationen via `yfinance`.\n",
    "3.  **Feature Engineering:** Berechnung von über 30 Kennzahlen und Signalen (z.B. gleitende Durchschnitte, RSI, MACD, Volatilität).\n",
    "4.  **Datenbereinigung:** Sicherstellung der Datenqualität für die Visualisierung.\n",
    "5.  **Speicherung:** Export der aufbereiteten Daten in zwei CSV-Dateien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65e4c50-8191-452b-b8ac-942e8eb505e2",
   "metadata": {},
   "source": [
    "# Bibliotheken\n",
    "\n",
    "**yfinance:** Erste Berührungspunkte in Taipeh bei der eigenständigen Erstellung von Backtesting-Programmen für Trading-Algorithmen.\n",
    "\n",
    "**pandas:** Die Nutzung war erforderlich und auch notwendig, da es sich um die wichtigste Bibliothek für die Datenverarbeitung handelt.\n",
    "\n",
    "**numpy:** Ebenfalls zwingend erforderlich und wurde für komplexere Berechnungen eingesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf241251-050d-44e8-8258-2c01c7a93b1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yfinance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myfinance\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01myf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yfinance'"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daead6f-a67a-4c0b-8865-e2a54c5ac830",
   "metadata": {},
   "source": [
    "# 1. Konfiguration\n",
    "Hier werden alle zentralen Parameter definiert. Das macht den Code flexibel und leicht anpassbar, ohne die Logik ändern zu müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31390df0-c833-4a35-9ea8-ad582db744a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = ['AAPL', 'MSFT', 'TSLA', 'NVDA', 'GOOGL', 'AMZN']\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2024-12-31'\n",
    "\n",
    "MA_WINDOWS = [12, 21, 50, 100, 200]\n",
    "RSI_PERIOD = 14\n",
    "MACD_FAST = 12\n",
    "MACD_SLOW = 26\n",
    "MACD_SIGNAL = 9\n",
    "BOLLINGER_WINDOW = 20\n",
    "BOLLINGER_STD = 2\n",
    "VOLATILITY_WINDOW = 20\n",
    "VOLATILITY_HISTORY = 252"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8afef0-d354-43a8-a04d-9e67f3517946",
   "metadata": {},
   "source": [
    "# 2. Hilfsfunktionen\n",
    "Wir definieren unsere Logik in wiederverwendbaren Funktionen. Das hält den Hauptteil des Skripts sauber und lesbar.\n",
    "- `get_ticker_info`: Holt Stammdaten wie Name, Sektor etc.\n",
    "- `calculate_indicators`: Das Herzstück – hier werden alle technischen Kennzahlen berechnet.\n",
    "- `classify_signals`: Übersetzt die Kennzahlen in einfach verständliche Signale (z.B. \"Überkauft\", \"Stabiler Aufwärtstrend\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd81b1-bc40-4fc7-af98-11962ea12980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_info(ticker_symbol):\n",
    "    try:\n",
    "        ticker = yf.Ticker(ticker_symbol)\n",
    "        info = ticker.info\n",
    "        return {\n",
    "            'Ticker': ticker_symbol,\n",
    "            'Name': info.get('longName', 'N/A'),\n",
    "            'Sektor': info.get('sector', 'N/A'),\n",
    "            'Branche': info.get('industry', 'N/A'),\n",
    "            'Land': info.get('country', 'N/A'),\n",
    "            'Website': info.get('website', 'N/A')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Ticker': ticker_symbol,\n",
    "            'Name': 'N/A', 'Sektor': 'N/A', 'Branche': 'N/A', 'Land': 'N/A', 'Website': 'N/A'\n",
    "        }\n",
    "\n",
    "\n",
    "def calculate_indicators(df):\n",
    "    for window in MA_WINDOWS:\n",
    "        df[f'MA{window}'] = df['Close'].rolling(window=window).mean()\n",
    "\n",
    "    # Tägliche Rendite und Volatilität\n",
    "    df['Return'] = df['Close'].pct_change()\n",
    "\n",
    "    # Rollierende Standardabweichung der täglichen Renditen\n",
    "    rolling_std = df['Return'].rolling(window=VOLATILITY_WINDOW).std()\n",
    "    # Annualisieren\n",
    "    df['Volatility'] = rolling_std * np.sqrt(252)\n",
    "\n",
    "    # RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=RSI_PERIOD).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=RSI_PERIOD).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    ema_fast = df['Close'].ewm(span=MACD_FAST, adjust=False).mean()\n",
    "    ema_slow = df['Close'].ewm(span=MACD_SLOW, adjust=False).mean()\n",
    "    df['MACD'] = ema_fast - ema_slow\n",
    "    df['MACD_Signal'] = df['MACD'].ewm(span=MACD_SIGNAL, adjust=False).mean()\n",
    "    df['MACD_Hist'] = df['MACD'] - df['MACD_Signal']\n",
    "\n",
    "    # Bollinger Bänder\n",
    "    df['Bollinger_Mid'] = df['Close'].rolling(window=BOLLINGER_WINDOW).mean()\n",
    "    df['Bollinger_Std'] = df['Close'].rolling(window=BOLLINGER_WINDOW).std()\n",
    "    df['Bollinger_Upper'] = df['Bollinger_Mid'] + (df['Bollinger_Std'] * BOLLINGER_STD)\n",
    "    df['Bollinger_Lower'] = df['Bollinger_Mid'] - (df['Bollinger_Std'] * BOLLINGER_STD)\n",
    "\n",
    "    # Normalisierter Kurs\n",
    "    df['Norm_Close'] = df['Close'] / df['Close'].iloc[0] * 100\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def classify_signals(df):\n",
    "\n",
    "    # Golden Cross / Death Cross Signal (mit NaN-Behandlung)\n",
    "    df['Trend_Signal'] = np.nan\n",
    "    df.loc[df['MA50'] > df['MA200'], 'Trend_Signal'] = 'Bullish (Golden Cross)'\n",
    "    df.loc[df['MA50'] < df['MA200'], 'Trend_Signal'] = 'Bearish (Death Cross)'\n",
    "\n",
    "    # RSI Status\n",
    "    df['RSI_Status'] = 'Neutral'\n",
    "    if 'RSI' in df.columns:\n",
    "        df.loc[df['RSI'] > 70, 'RSI_Status'] = 'Überkauft'\n",
    "        df.loc[df['RSI'] < 30, 'RSI_Status'] = 'Überverkauft'\n",
    "\n",
    "    df['Sentiment'] = 'Seitwärts / Neutral'\n",
    "\n",
    "    if 'Volatility' in df.columns:\n",
    "        vol_q75 = df['Volatility'].rolling(window=VOLATILITY_HISTORY, min_periods=1).quantile(0.75)\n",
    "        vol_q25 = df['Volatility'].rolling(window=VOLATILITY_HISTORY, min_periods=1).quantile(0.25)\n",
    "\n",
    "        conditions = [\n",
    "            (df['Trend_Signal'] == 'Bullish (Golden Cross)') & (df['Volatility'] < vol_q25),\n",
    "            (df['Trend_Signal'] == 'Bullish (Golden Cross)') & (df['Volatility'] > vol_q75),\n",
    "            (df['Trend_Signal'] == 'Bearish (Death Cross)') & (df['Volatility'] > vol_q75),\n",
    "            (df['Trend_Signal'] == 'Bearish (Death Cross)') & (df['Volatility'] < vol_q25)\n",
    "        ]\n",
    "        choices = [\n",
    "            'Stabiler Aufwärtstrend',\n",
    "            'Volatiler Aufwärtstrend',\n",
    "            'Panischer Abwärtstrend',\n",
    "            'Schwacher Abwärtstrend'\n",
    "        ]\n",
    "\n",
    "        mask = df['Trend_Signal'].notna() & df['Volatility'].notna() & vol_q25.notna() & vol_q75.notna()\n",
    "\n",
    "        df.loc[mask, 'Sentiment'] = np.select(\n",
    "            [c[mask] for c in conditions],\n",
    "            choices,\n",
    "            default='Seitwärts / Neutral'\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6c014-794a-493f-bb45-283a9d4ab9b1",
   "metadata": {},
   "source": [
    "# 3. Daten-Pipeline ausführen\n",
    "Jetzt werden die Funktionen in einer Schleife für jeden Ticker auf aufgerufen. Der Fortschritt wird live ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae783c-dcbb-49fb-84ea-e3331782fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_info = []\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    # Statische Infos abrufen\n",
    "    info_data = get_ticker_info(ticker)\n",
    "    all_info.append(info_data)\n",
    "\n",
    "    # Historische Kursdaten abrufen\n",
    "    try:\n",
    "        yf_ticker = yf.Ticker(ticker)\n",
    "        data = yf_ticker.history(start=START_DATE, end=END_DATE, auto_adjust=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Download für {ticker}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame) or data.empty:\n",
    "        print(f\" Keine gültigen DataFrame-Daten für {ticker} empfangen - überspringe.\")\n",
    "        continue\n",
    "\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    cols_to_numeric = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    for col in cols_to_numeric:\n",
    "        if col in data.columns:\n",
    "            try:\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "            except TypeError:\n",
    "                print(f\"TICKER: {ticker}, SPALTE: '{col}'\")\n",
    "                print(f\"Der Datentyp des 'data'-Objekts ist: {type(data)}\")\n",
    "                print(f\"Die Spalten des 'data'-Objekts sind: {data.columns.to_list()}\")\n",
    "                print(f\"Der Datentyp der problematischen Spalte '{col}' ist: {type(data[col])}\")\n",
    "                print(data[col].head())\n",
    "                raise\n",
    "        else:\n",
    "            print(f\"Hinweis: Spalte '{col}' wurde in den Daten für {ticker} nicht gefunden.\")\n",
    "\n",
    "    original_rows = len(data)\n",
    "    data.dropna(subset=['Close'], inplace=True)\n",
    "    if len(data) < original_rows:\n",
    "        print(f\" {original_rows - len(data)} fehlerhafte Zeile(n) für {ticker} entfernt.\")\n",
    "\n",
    "    # Indikatoren berechnen\n",
    "    data = calculate_indicators(data)\n",
    "\n",
    "    # Signale klassifizieren\n",
    "    data = classify_signals(data)\n",
    "\n",
    "    # Daten für Zusammenführung vorbereiten\n",
    "    data['Ticker'] = ticker\n",
    "    all_data.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4475bf9-45c8-4840-b508-8c9d710dd5db",
   "metadata": {},
   "source": [
    "# 4. Finale Daten zusammenführen und speichern\n",
    "Die individuellen Daten der Ticker werden in zwei finale DataFrames kombiniert und als CSV-Dateien gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7a14a-10be-414a-86aa-2069a88885c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeuge finale DataFrames\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "info_df = pd.DataFrame(all_info)\n",
    "\n",
    "# Bereinige Spalten\n",
    "final_df.drop(columns=['Bollinger_Std'], inplace=True, errors='ignore')\n",
    "\n",
    "# Speichere die Ergebnisse als CSV-Dateien\n",
    "final_df.to_csv(\"aktien_dashboard_enhanced.csv\", index=False, float_format=\"%.4f\")\n",
    "info_df.to_csv(\"ticker_info_dynamic.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
